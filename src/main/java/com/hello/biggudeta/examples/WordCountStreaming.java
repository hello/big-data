package com.hello.biggudeta.examples;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import scala.Tuple2;

import java.util.Arrays;

/**
 * Created by ksg on 3/25/16
 * To run, go to spark/bin
 *   `spark-submit --class com.example.WordCountStreaming --master local[4] \
 *     /Users/kingshy/DEV/Spark/Java/spark-examples/target/spark-examples-1.0-SNAPSHOT.jar localhost 9999`
 *
 *     https://github.com/apache/spark/blob/master/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java
 */

public class WordCountStreaming {

    public static void main(String[] args) {
        if (args.length < 2) {
            System.err.println("Usage: JavaNetworkWordCount <stream-hostname> <port>");
            System.exit(1);
        }

        // setup spark streaming
        final SparkConf conf = new SparkConf().setAppName("WordCountStreaming").setMaster("local[2]");

        // 1. initialize streaming context
        final Duration windowSize = Durations.seconds(10);
        final JavaStreamingContext jssc = new JavaStreamingContext(conf, windowSize);


        // 2. Define the input sources by creating input DStreams.
        //
        // Create a JavaReceiverInputDStream on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        // Note that no duplication in storage level only for running locally.
        // Replication necessary in distributed scenario for fault tolerance.
        //
        // connect to a data stream, tcp data server, use netcat nc -lk 9999
        final String hostname = args[0];
        final Integer port = Integer.parseInt(args[1]);
        final JavaReceiverInputDStream<String> lines = jssc.socketTextStream(hostname, port, StorageLevels.MEMORY_AND_DISK_SER);


        // 3. Define the streaming computations by applying transformation and output operations to DStreams.
        // split lines into word streams
        final JavaDStream<String> words = lines.flatMap(new FlatMapFunction<String, String>() {
            @Override
            public Iterable<String> call(String s) throws Exception {
                return Arrays.asList(s.split(" "));
            }
        });

        // create (word, 1) pair
        final JavaPairDStream<String, Integer> wordPairs = words.mapToPair(new PairFunction<String, String, Integer>() {
            @Override
            public Tuple2<String, Integer> call(String s) throws Exception {
                return new Tuple2<String, Integer>(s, 1);
            }
        });

        // count the pairs (reduce)
        final JavaPairDStream<String, Integer> counts = wordPairs.reduceByKey(new Function2<Integer, Integer, Integer>() {
            @Override
            public Integer call(Integer integer, Integer integer2) throws Exception {
                return integer + integer2;
            }
        });

        // print first 10 elements
        counts.print();


        // 4. Start receiving data and processing it
        jssc.start();


        // 5. Wait for the processing to be stopped (manually or due to any error)
        jssc.awaitTermination();


        // 6. The processing can be manually stopped using streamingContext.stop()
    }
}
